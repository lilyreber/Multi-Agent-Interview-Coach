{
  "participant_name": "Имамутдинова Лилия Рафаильевна",
  "turns": [
    {
      "turn_id": 1,
      "agent_visible_message": "Привет! Расскажите, пожалуйста, о вашем профессиональном пути в сфере машинного обучения: какие ключевые этапы, роли и решения определили вашу карьеру, какие команды и проекты вы вели и какие бизнес‑результаты это принесло?",
      "user_message": "Привет! Я  Senior Machine Learning Engineer. Мой стек — это Kubernetes, CSS, Blockchain",
      "internal_thoughts": "[Observer] Ответ кандидата очень короткий и поверхностный. Для роли Senior Machine Learning Engineer перечисленные технологии выглядят частично несоответствующими: Kubernetes — релевантно (инфраструктура/деплой моделей), а CSS — фронтенд-стиль, обычно не ключевой навык для senior ML-специалиста; Blockchain может иметь отношение к ML только в узких сценариях (например, верификация данных, децентрализованные данные), но без пояснения вызывает вопросы. Кандидат не упомянул базовые и ожидаемые для Senior ML навыки: знание фреймворков (PyTorch/TensorFlow), опыт работы с данными (ETL, большие данные), эксперименты и MLOps (CI/CD, мониторинг, feature store), алгоритмы машинного обучения, метрики качества, работу с GPU/распределённым обучением, а также примеры проектов и результаты в продакшне. Короткая самопрезентация может означать либо невнимательность, либо попытку заявить «модные» технологии без глубины. Нужны уточняющие вопросы и проверка на конкретных примерах/доказательствах.\n                                  [Observer] Рекомендации: ['Спросить кандидата конкретно, какие ML-фреймворки и библиотеки он использует (PyTorch, TensorFlow, scikit-learn, XGBoost и т.д.) и привести недавний пример проекта с архитектурой модели и метриками.', 'Выяснить, как именно Kubernetes используется им в контексте ML: для оркестрации тренировочных задач, развертывания моделей (serving), автоматического масштабирования inference, запуска CI/CD пайплайнов или другого сценария. Попросить схему/описание процесса деплоя.', 'Попросить объяснить, почему в стекe указан CSS: использовал ли он фронтенд для ML-дашбордов, визуализации результатов, UI для аннотации данных? Попросить пример репозитория или скриншот/демо.', 'Уточнить роль Blockchain в его опыте: как он применял блокчейн в ML-проектах (достоверность данных, аудиторские треки, децентрализованные данные) и привести конкретный кейс с технологическим стеком и результатами.', 'Проверить опыт работы в продакшн: сколько моделей развернуто, как осуществляется мониторинг качества и дрейфа модели, какие SLA/SLO, как решал инциденты в проде.', 'Если кандидат не может ответить уверенно — перейти к уточняющим/контрольным вопросам по базовым ML темам (обучение/валидация, регуляризация, выбор метрик, отбор признаков, обработка пропусков, влияние дисбаланса классов).', 'Если ответы убедительны — усложнить задачу: попросить спроектировать систему для обучения и онлайн-выдачи модели с требованиями по задержке и масштабируемости, объяснить trade-offs (latency vs throughput, consistency vs availability) и конкретные реализации в Kubernetes.', 'Предложить техническое задание/домашнее задание или парное упражнение: развернуть простую модель в k8s с CI/CD и мониторингом (температуру/throughput/latency и drift detection).']\n                                  [Interviewer] Сложность скорректирована: 1"
    },
    {
      "turn_id": 2,
      "agent_visible_message": "Можете уточнить этот момент? Какие ML‑фреймворки и библиотеки вы обычно используете (PyTorch, TensorFlow, scikit‑learn, XGBoost и т.д.) — и приведите недавний проект: опишите архитектуру модели, характер и объём данных, как проходили обучение и валидация, ключевые метрики и текущий статус (локально/в проде/развёрнут на k8s и т.п.)?",
      "user_message": "Обучаем модель методом обратного распространения ошибки через DNS-сервер, чтобы улучшить верстку сайта",
      "internal_thoughts": "[Observer] Ответ кандидата некорректен и демонстрирует либо глубокую путаницу терминов, либо попытку шутки/обхода вопроса. Метод обратного распространения ошибки (backpropagation) — это алгоритм для обучения параметров нейронной сети внутри вычислительного графа; он выполняется в рамках процесса обучения (CPU/GPU/TPU) и никак не «передаётся через DNS‑сервер». DNS (Domain Name System) — это система разрешения имён в IP‑адреса для сетевых запросов; её задача не связана с передачей градиентов, обучением моделей или улучшением верстки. Также «улучшить верстку сайта» — задача приложения/фронтенда и продуктовой аналитики; подходы с ML возможны (A/B‑тесты, ранжирование, генерация CSS), но оформляются совсем иначе: сбор данных о пользователях/сессиях, метрики (CTR, конверсии, время на странице), офлайн/онлайн эксперименты, модели и система доставки изменений. Такое смешение терминов у старшего ML‑инженера неприемлемо без пояснений.\n                                  [Observer] Рекомендации: ['Явно укажите кандидату, что его утверждение неверно: попросите пояснить, что он имел в виду под «обучением через DNS‑сервер».', 'Если кандидат не в состоянии объяснить — считайте это серьёзной проблемой по базовым знаниям (сеть/стек и ML).', 'Если кандидат окончательно смутился, задайте наводящие вопросы, чтобы понять уровень непонимания: например, попросите описать, где именно в пайплайне обучения происходит backprop и какие компоненты инфраструктуры задействованы.', 'Проверьте понимание веб‑инфраструктуры: спросите, что такое DNS, CDN, HTTP(S), как происходит рендеринг страницы и где можно вмешаться для оптимизации верстки.', 'Переведите разговор на практическую задачу: попросите спроектировать систему для «оптимизации верстки сайта» с использованием ML — попросите пройти ключевые шаги: формулировка цели, метрики, сбор данных, выбор модели, офлайн‑оценка, онлайн‑эксперименты, деплой и мониторинг.', 'Если хотите усложнить (кандидат оправдался и показал базовые знания), попросите детально описать: feature store, частоту обновления модели, требования к латентности при A/B и при персонализации, используемые алгоритмы (bandits, contextual bandits, learning‑to‑rank), и как обеспечить откат/безопасность изменений в UI.', 'Попросите привести конкретный пример реализации: формат данных для обучения (events, impressions, clicks), метрику успеха (например, uplift в конверсии), архитектуру обучения и сервинга (офлайн тренировочный кластер, модельный API/edge), и как мониторить деградацию модели.']\n                                  [Interviewer] Сложность скорректирована: 1"
    },
    {
      "turn_id": 3,
      "agent_visible_message": "Можете уточнить этот момент? Какие ML‑фреймворки и библиотеки вы обычно используете (PyTorch, TensorFlow, scikit‑learn, XGBoost и т.д.) — и приведите недавний проект: опишите архитектуру модели, характер и объём данных, как проходили обучение и валидация, ключевые метрики и текущий статус (локально/в проде/развёрнут на k8s и т.п.)?",
      "user_message": "Это современный подход \"Cross-Layer Optimization\". Вы что, не читали последние статьи на arXiv? Мы так сократили косты на 40%",
      "internal_thoughts": "[Observer] Кандидат дал короткий, высокомерный ответ с маркетинговой формулировкой («Cross-Layer Optimization», «сократили косты на 40%») и ссылкой на «статьи на arXiv», но не привёл никаких деталей или доказательств. Это поведение вызывает несколько замечаний: 1) термин — слишком общий и может скрывать множество разных техник (от compiler optimizations до co-design HW/SW/NN); 2) числовое заявление (40%) непроверяемо без контекста (какие метрики, базовая конфигурация, нагрузка, оборудование); 3) тон — грубый, что влияет на командную совместимость.\n\nНа этапе Senior ожидалось бы: конкретное определение подхода (какие слои/уровни оптимизируются), формулировка задачи оптимизации (объектив и ограничения), описание алгоритма/метода (градиентный, RL, MILP, эвристика), эксперименты (baseline, метрики, набор данных, среда/железо), и ссылки на работы или репозиторий для проверки. У кандидата этого нет — необходимо углубление или запрос подтверждающих материалов.\n                                  [Observer] Рекомендации: ['Попросить назвать конкретные арXiv-статьи (название/авторы/год) и кратко резюмировать основной вклад каждой.', 'Спросить точное определение «Cross-Layer Optimization» в их контексте: какие уровни включены (архитектура сети, компиляция, ядра HW, placement, quantization и т.д.).', 'Попросить математическую формулировку: что является целевой функцией, какие переменные оптимизируются, какие ограничения?', 'Уточнить метод оптимизации: какой алгоритм/поиск был использован, почему выбран именно он, как решается дискретность/непрерывность?', 'Попросить подробности по экспериментам: какая модель/набор данных/нагрузка, на каком железе, сравнение с каким baseline, как вычислена «экономия 40%» (время/энергия/стоимость)?', 'Запросить ablation study и устойчивость решения: как метод ведёт себя на других моделях/данных/платформах?', 'Попросить код/скрипты и воспроизводимость результатов или хотя бы чек-лист измерений (метрики, конфигурации, seed).', 'Если кандидат уклоняется или не может ответить — отметить возможный блеф и перейти к более прикладным вопросам по CI/CD, тестированию/деплою оптимизаций.', 'Если кандидат даёт исчерпывающие ответы — усложнить задачу: попросить вывести оптимизационную задачу формально и обсудить сложность/масштабируемость решения и trade-offs (латентность vs throughput vs energy vs accuracy).']\n                                  [Interviewer] Сложность скорректирована: 1"
    },
    {
      "turn_id": 4,
      "agent_visible_message": "Можете уточнить этот момент? Опишите конкретные практики и проверки, которые вы используете, чтобы предотвратить feature leakage и lookahead bias при формировании офлайн‑датасета для задачи предсказания будущего события (например churn или next‑purchase): как вы формализуете временные окна/таймстемпы, делаете train/validation/test split по времени, какие фичи исключаете или агрегируете, какие автоматические тесты/юнит‑тесты пишете и как проверяете, что в офлайн‑данных нет утечки информации из будущего — приведите 2–3 конкретных примера (псевдокод/SQL или короткое описание), которые вы применяли на практике.",
      "user_message": "Кстати, а ваша компания уже перешла на протокол Hyper-Text-Quantum-Transfer (HTQT)? Без него же микросервисы не могут общаться быстрее скорости света. Это сейчас стандарт индустрии",
      "internal_thoughts": "[Observer] Кандидат явно пошутил или отвлёкся: протокола Hyper-Text-Quantum-Transfer (HTQT) не существует в профессиональной сети/литературе, и утверждение «микросервисы не могут общаться быстрее скорости света» абсурдно с точки зрения физики (ничто не может передавать информацию быстрее скорости света в вакууме). Если кандидат говорил серьёзно и утверждает, что это «стандарт индустрии», это ложь/невежество. Правильные реальные технологии, которые сейчас применяют для низкой латентности в микросервисах: HTTP/2, gRPC (HTTP/2 + protobuf), QUIC/HTTP/3, бинарные протоколы, сервис-меши (Istio, Linkerd) и оптимизации вроде connection pooling, keep-alive, TLS+session resumption, batching, горизонтальное масштабирование. Также полезно помнить физическое ограничение на задержку: скорость света даёт нижнюю границу (примерно ~3.3 μs на км в вакууме, ~5 μs/км в оптоволокне), что важно при обсуждении распределённых систем и географически распределённой архитектуры. В целом — ответ кандидата не соответствует фактам; возможно это проверка чувства юмора/культуры команды, но нужно уточнить намерение и дальше проверить реальные знания по сетевым протоколам, латентности и дизайну распределённых систем.\n                                  [Observer] Рекомендации: ['Сразу уточнить: вы шутите или считаете, что это реальный протокол? (проверка честности / юмора)', 'Если это шутка — дать шанс, но быстро перевести разговор в техническое русло: «Расскажите, какие реальные протоколы и практики вы используете для уменьшения задержки между микросервисами?»', 'Если кандидат утверждает серьёзно — попросить дать ссылки/документацию на HTQT; отсутствие ссылок — явный красный флаг.', 'Задать конкретные технические вопросы для проверки глубины знаний: как HTTP/2 и QUIC уменьшают задержку по сравнению с HTTP/1.1; когда выбрать gRPC vs REST; влияние TLS_handshake и как его оптимизировать (session resumption, false start, TLS 1.3).', 'Попросить оценить вклад физических ограничений в задержку: попросить грубую оценку минимальной задержки между еврой и США (или между двумя датацентрами на 1000 км) и объяснить, какие оптимизации позволяют этим ограничением противостоять (кеширование, деградация качества, репликация данных).', 'Проверить практические навыки: попросить предложить план замера/бенчмаркинга межсерверной задержки (инструменты: wrk/ghz/vegeta, трассировка распределённых запросов, p99/p95), и какие метрики и тесты вы бы использовали для принятия архитектурного решения.', 'Если поведение кандидата — юмор/ирония — оценить мягкие навыки: уместность шутки, понимание аудитории. Если это попытка ввести в заблуждение — рассмотреть как негативный сигнал для старшего уровня.']\n                                  [Interviewer] Сложность скорректирована: 1"
    },
    {
      "turn_id": 5,
      "agent_visible_message": "Нет — протокола Hyper-Text-Quantum-Transfer (HTQT) не существует и это не индустриальный стандарт. Мы используем проверенные протоколы и практики (HTTP/2, HTTP/3/QUIC, gRPC, оптимизации сети и сервис-меши).  \nВозвращаюсь к интервью.\n\nСледующий вопрос: Опишите практический план профилирования и снижения задержки инференса для продовой PyTorch‑модели (цель: p95 < 50 ms): какие метрики и инструменты будете измерять, как сравнительно оцените CPU vs GPU и FP32 vs FP16/INT8, какие конкретные оптимизации внедрите (batching, torch.jit/ONNX/TensorRT, квантование, градиент‑пропуск и т.д.), и как протестируете эти изменения на продовой нагрузке включая метрики мониторинга и сценарии отката?",
      "user_message": "Странно, что вы не знаете. Об этом же писал Илон Тьюринг в своей книге \"Искусство блокчейн-компиляции\". Я всегда следую его заветам",
      "internal_thoughts": "[Observer] Кандидат дал странный, сомнительный ответ — он утверждает, что некая книга «Искусство блокчейн-компиляции» написана «Илоном Тьюрингом». Это фактически неверно или, как минимум, требует проверки: известного автора «Илон Тьюринг» не существует (возможно путаница с Alan Turing или Elon Musk), и по названию книги нет известных ссылок. Тон ответа («Странно, что вы не знаете») агрессивно-надменный — это тревожный сигнал по коммуникативной культуре. Возможные объяснения: кандидат шутит/троллит, пытается уклониться от ответа, или действительно дал ложную информацию/ошибся. Нужно быстро прояснить мотив — это даст много информации о честности, самокритике и коммуникации кандидата.\n                                  [Observer] Рекомендации: ['Сразу попросите уточнить — спросите, имел ли кандидат в виду реального автора и может ли привести ссылку/цитату из упомянутой книги.', 'Если кандидат не может привести источник — вежливо укажите на ошибку (нет автора «Илон Тьюринг», книга неизвестна) и посмотрите на его реакцию: признаёт ли ошибку и исправляет ли рассказ.', 'Если это была шутка/тролльство — предупредите о неприемлемости такого тона и попросите отвечать серьёзно; оцените, как кандидат принимает такую корректировку.', 'Переведите разговор на конкретику: попросите объяснить понятие «блокчейн-компиляция» своими словами и описать, как это соотносится с задачами ML-инженера.', 'Задайте технические уточняющие вопросы, чтобы проверить профуровень: примеры — как компилировать модели для выполнения в EVM/wasm, ограничения газ/памяти, стратегии оптимизации (квантизация, прунинг, операторные замены), примеры реальных проектов (eWASM, zkVM, ONNX->WASM и т.д.).', 'Проверьте культурную совместимость: спросите, как кандидат реагирует на корректировку фактов и попросите привести пример момента, когда он признавал ошибку и что делал дальше.']\n                                  [Interviewer] Сложность скорректирована: 1"
    },
    {
      "turn_id": 6,
      "agent_visible_message": "Фидбэк сгенерирован",
      "user_message": "",
      "internal_thoughts": "Финальный фидбэк: {\"verdict\": {\"grade\": \"Senior\", \"hiring_recommendation\": \"No Hire\", \"confidence_score\": 88}, \"hard_skills\": {\"confirmed_skills\": [\"Kubernetes — кандидат упомянул в стеке (есть указание на знание инфраструктуры/оркестрации)\"], \"knowledge_gaps\": [{\"topic\": \"Основы обучения нейронных сетей (backpropagation и пайплайн обучения)\", \"issue\": \"Кандидат неверно связал backpropagation с DNS и описал обучение в некорректных терминах, что указывает на слабое понимание базового ML‑пайплайна.\", \"correct_answer\": \"Backpropagation — алгоритм вычисления градиентов в вычислительном графе нейронной сети, выполняется на CPU/GPU/TPU в рамках шага оптимизации. Передача градиентов между узлами в распределённом обучении происходит по сетевым протоколам (RPC), но не через DNS как протокол передачи данных. DNS — система разрешения имён, не связанная с обучением.\", \"resources\": [\"https://cs231n.github.io/neural-networks-3/ (объяснение backprop)\", \"https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\", \"https://www.tensorflow.org/guide/keras/train_and_evaluate\"]}, {\"topic\": \"ML-фреймворки и экосистема (PyTorch/TensorFlow/ONNX и т.д.)\", \"issue\": \"Кандидат не назвал используемые фреймворки и библиотеки, не дал примеров кода/архитектур — невозможно подтвердить практический опыт.\", \"correct_answer\": \"Ожидается умение описать стек (например, PyTorch/TensorFlow для обучения, scikit-learn/XGBoost для табличных задач, ONNX/TensorRT для оптимизации и сервинга), привести конкретный проект с архитектурой модели, метриками и статусом развёртывания.\", \"resources\": [\"https://pytorch.org/docs/stable/\", \"https://www.tensorflow.org/\", \"https://onnx.ai/\"]}, {\"topic\": \"Деплой моделей и MLOps (serving, мониторинг, CI/CD, drift detection)\", \"issue\": \"Кандидат не описал опыт продового развёртывания моделей, мониторинга качества, SLO/SLA, инцидент-менеджмента и практик rollback/CI.\", \"correct_answer\": \"Деплой включает: подготовку модели (export, оптимизация), создание служебного API/контейнера, автоматизированный CI/CD для моделей, мониторинг latency/throughput/accuracy/drift и процессы отката. В Kubernetes обычно используют контейнеры, ingress/service mesh, autoscaling и системы мониторинга (Prometheus, Grafana), feature store и pipelines (Kubeflow, Airflow).\", \"resources\": [\"https://www.kubeflow.org/\", \"https://ml-ops.org/\", \"https://prometheus.io/ (мониторинг)\", \"https://grafana.com/\"]}, {\"topic\": \"Инференс‑оптимизация и профилирование (FP32/FP16/INT8, TensorRT, batching)\", \"issue\": \"Кандидат уклонился от технического ответа по профилированию латентности и оптимизациям инференса.\", \"correct_answer\": \"План: собрать p50/p95/p99 latency, throughput, CPU/GPU utilization; профилировать модель (torch.profiler, nvprof), сравнить CPU vs GPU и точность FP32/FP16/INT8; попробовать JIT/ONNX->TensorRT, динамический/статический batching, квантование с калибровкой и fallback-стратегии; нагрузочное тестирование и мониторинг в проде с откатом по SLO.\", \"resources\": [\"https://pytorch.org/tutorials/recipes/optimizing_torchscript_runtime.html\", \"https://developer.nvidia.com/tensorrt\", \"https://pytorch.org/docs/stable/profiler.html\"]}, {\"topic\": \"Сетевые протоколы и распределённые системы (DNS, HTTP/2, QUIC, gRPC)\", \"issue\": \"Кандидат демонстрировал непонимание роли DNS и упоминал несуществующий протокол (HTQT), что ставит под сомнение знания в области сетевой архитектуры и задержки.\", \"correct_answer\": \"DNS — служба разрешения имён в IP; для низкой латентности используют протоколы/стеки: HTTP/2, HTTP/3/QUIC, gRPC (HTTP/2) и оптимизации (persistent connections, TLS session resumption, connection pooling). Физический предел задержки определяется скоростью света; архитектурные решения (кеширование, репликация, edge) помогают уменьшить видимую задержку.\", \"resources\": [\"https://grpc.io/docs/\", \"https://datatracker.ietf.org/doc/html/rfc9000 (QUIC)\", \"https://www.cloudflare.com/learning/ddos/glossary/http2/ (HTTP/2 overview)\"]}, {\"topic\": \"Экспериментальная методология и доказательства (репродуцируемость, отчёты)\", \"issue\": \"Кандидат делал громкие утверждения (экономия 40%) без деталей, абляций или ссылок на репозиторий/методологию.\", \"correct_answer\": \"При заявлении экономии ожидаются: формулировка метрики (время/энергия/сost), baseline, среда тестирования, аппаратная конфигурация, набор данных, seed, статистическая значимость, ablation study и код/скрипты для воспроизведения.\", \"resources\": [\"https://arxiv.org/abs/1806.03335 (пример требования к воспроизводимости в ML)\", \"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/woodside2014.pdf (методы репродуцируемости/бенчмаркинга)\"]}]}, \"soft_skills\": {\"clarity\": \"Низкая — ответы крайне короткие, часто запутанные, много несоответствий между терминами; кандидат не давал структурированных примеров или деталей.\", \"honesty\": \"Вызывает сомнения — кандидат несколько раз сделал очевидно неверные или выдуманные утверждения (HTQT, «Илон Тьюринг», обучение через DNS) и не предоставил корректных источников; не было признаков искреннего признания незнания.\", \"engagement\": \"Низкая — кандидат не задавал встречных уточняющих вопросов, не давал примеров или материалов (репозиторий, диаграммы), иногда отвечал иронично/агрессивно вместо развёрнутого объяснения.\"}, \"roadmap\": {\"recommendations\": [\"Освежить и закрепить базовые ML-концепции: backpropagation, оптимизация, валидация и предотвращение утечек признаков (feature leakage).\", \"Получить практический опыт с крупными фреймворками: PyTorch и/или TensorFlow — уметь показать проекты, код и метрики.\", \"Отработать развёртывание моделей в продакшн: контейнеризация, K8s‑serving, CI/CD для моделей, мониторинг (Prometheus/Grafana), стратегии rollback и SLO.\", \"Прокачать навыки инференс‑оптимизаций: профилирование, квантование (FP16/INT8), ONNX/TensorRT, batching и тестирование p95/p99.\", \"Укрепить знания распределённых систем и сетей: роль DNS, HTTP/2, QUIC, gRPC, влияние физической задержки и практики измерения latency.\", \"Научиться грамотно оформлять экспериментальные результаты: как готовить reproducible experiments, писать ablation studies и предоставлять код/скрипты.\", \"Работать над коммуникативными навыками: давать структурированные ответы, избегать троллинга/недостоверных ссылок, признавать незнание и предлагать дальнейшие шаги.\"], \"resources\": [\"Курсы и туториалы: https://www.coursera.org/specializations/deep-learning, https://www.fast.ai/\", \"PyTorch Tutorials: https://pytorch.org/tutorials/\", \"TensorFlow Guide: https://www.tensorflow.org/learn\", \"MLOps / deployment: https://www.kubeflow.org/, https://ml-ops.org/\", \"Инференс и оптимизация: https://developer.nvidia.com/tensorrt, https://onnx.ai/\", \"Распределённые системы и сети: https://grpc.io/docs/, https://datatracker.ietf.org/doc/html/rfc9000 (QUIC), \\\"Designing Data-Intensive Applications\\\" — M. Kleppmann\", \"Экспериментальная методология: https://arxiv.org/abs/1806.03335, \\\"Hidden Technical Debt in Machine Learning Systems\\\" — Sculley et al.\", \"Книги/руководства: \\\"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\\\" — A. Géron; \\\"Machine Learning Engineering\\\" / книги по MLOps\"]}}"
    }
  ],
  "internal_dialogues": [],
  "final_feedback": {
    "verdict": {
      "grade": "Senior",
      "hiring_recommendation": "No Hire",
      "confidence_score": 88
    },
    "hard_skills": {
      "confirmed_skills": [
        "Kubernetes — кандидат упомянул в стеке (есть указание на знание инфраструктуры/оркестрации)"
      ],
      "knowledge_gaps": [
        {
          "topic": "Основы обучения нейронных сетей (backpropagation и пайплайн обучения)",
          "issue": "Кандидат неверно связал backpropagation с DNS и описал обучение в некорректных терминах, что указывает на слабое понимание базового ML‑пайплайна.",
          "correct_answer": "Backpropagation — алгоритм вычисления градиентов в вычислительном графе нейронной сети, выполняется на CPU/GPU/TPU в рамках шага оптимизации. Передача градиентов между узлами в распределённом обучении происходит по сетевым протоколам (RPC), но не через DNS как протокол передачи данных. DNS — система разрешения имён, не связанная с обучением.",
          "resources": [
            "https://cs231n.github.io/neural-networks-3/ (объяснение backprop)",
            "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html",
            "https://www.tensorflow.org/guide/keras/train_and_evaluate"
          ]
        },
        {
          "topic": "ML-фреймворки и экосистема (PyTorch/TensorFlow/ONNX и т.д.)",
          "issue": "Кандидат не назвал используемые фреймворки и библиотеки, не дал примеров кода/архитектур — невозможно подтвердить практический опыт.",
          "correct_answer": "Ожидается умение описать стек (например, PyTorch/TensorFlow для обучения, scikit-learn/XGBoost для табличных задач, ONNX/TensorRT для оптимизации и сервинга), привести конкретный проект с архитектурой модели, метриками и статусом развёртывания.",
          "resources": [
            "https://pytorch.org/docs/stable/",
            "https://www.tensorflow.org/",
            "https://onnx.ai/"
          ]
        },
        {
          "topic": "Деплой моделей и MLOps (serving, мониторинг, CI/CD, drift detection)",
          "issue": "Кандидат не описал опыт продового развёртывания моделей, мониторинга качества, SLO/SLA, инцидент-менеджмента и практик rollback/CI.",
          "correct_answer": "Деплой включает: подготовку модели (export, оптимизация), создание служебного API/контейнера, автоматизированный CI/CD для моделей, мониторинг latency/throughput/accuracy/drift и процессы отката. В Kubernetes обычно используют контейнеры, ingress/service mesh, autoscaling и системы мониторинга (Prometheus, Grafana), feature store и pipelines (Kubeflow, Airflow).",
          "resources": [
            "https://www.kubeflow.org/",
            "https://ml-ops.org/",
            "https://prometheus.io/ (мониторинг)",
            "https://grafana.com/"
          ]
        },
        {
          "topic": "Инференс‑оптимизация и профилирование (FP32/FP16/INT8, TensorRT, batching)",
          "issue": "Кандидат уклонился от технического ответа по профилированию латентности и оптимизациям инференса.",
          "correct_answer": "План: собрать p50/p95/p99 latency, throughput, CPU/GPU utilization; профилировать модель (torch.profiler, nvprof), сравнить CPU vs GPU и точность FP32/FP16/INT8; попробовать JIT/ONNX->TensorRT, динамический/статический batching, квантование с калибровкой и fallback-стратегии; нагрузочное тестирование и мониторинг в проде с откатом по SLO.",
          "resources": [
            "https://pytorch.org/tutorials/recipes/optimizing_torchscript_runtime.html",
            "https://developer.nvidia.com/tensorrt",
            "https://pytorch.org/docs/stable/profiler.html"
          ]
        },
        {
          "topic": "Сетевые протоколы и распределённые системы (DNS, HTTP/2, QUIC, gRPC)",
          "issue": "Кандидат демонстрировал непонимание роли DNS и упоминал несуществующий протокол (HTQT), что ставит под сомнение знания в области сетевой архитектуры и задержки.",
          "correct_answer": "DNS — служба разрешения имён в IP; для низкой латентности используют протоколы/стеки: HTTP/2, HTTP/3/QUIC, gRPC (HTTP/2) и оптимизации (persistent connections, TLS session resumption, connection pooling). Физический предел задержки определяется скоростью света; архитектурные решения (кеширование, репликация, edge) помогают уменьшить видимую задержку.",
          "resources": [
            "https://grpc.io/docs/",
            "https://datatracker.ietf.org/doc/html/rfc9000 (QUIC)",
            "https://www.cloudflare.com/learning/ddos/glossary/http2/ (HTTP/2 overview)"
          ]
        },
        {
          "topic": "Экспериментальная методология и доказательства (репродуцируемость, отчёты)",
          "issue": "Кандидат делал громкие утверждения (экономия 40%) без деталей, абляций или ссылок на репозиторий/методологию.",
          "correct_answer": "При заявлении экономии ожидаются: формулировка метрики (время/энергия/сost), baseline, среда тестирования, аппаратная конфигурация, набор данных, seed, статистическая значимость, ablation study и код/скрипты для воспроизведения.",
          "resources": [
            "https://arxiv.org/abs/1806.03335 (пример требования к воспроизводимости в ML)",
            "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/woodside2014.pdf (методы репродуцируемости/бенчмаркинга)"
          ]
        }
      ]
    },
    "soft_skills": {
      "clarity": "Низкая — ответы крайне короткие, часто запутанные, много несоответствий между терминами; кандидат не давал структурированных примеров или деталей.",
      "honesty": "Вызывает сомнения — кандидат несколько раз сделал очевидно неверные или выдуманные утверждения (HTQT, «Илон Тьюринг», обучение через DNS) и не предоставил корректных источников; не было признаков искреннего признания незнания.",
      "engagement": "Низкая — кандидат не задавал встречных уточняющих вопросов, не давал примеров или материалов (репозиторий, диаграммы), иногда отвечал иронично/агрессивно вместо развёрнутого объяснения."
    },
    "roadmap": {
      "recommendations": [
        "Освежить и закрепить базовые ML-концепции: backpropagation, оптимизация, валидация и предотвращение утечек признаков (feature leakage).",
        "Получить практический опыт с крупными фреймворками: PyTorch и/или TensorFlow — уметь показать проекты, код и метрики.",
        "Отработать развёртывание моделей в продакшн: контейнеризация, K8s‑serving, CI/CD для моделей, мониторинг (Prometheus/Grafana), стратегии rollback и SLO.",
        "Прокачать навыки инференс‑оптимизаций: профилирование, квантование (FP16/INT8), ONNX/TensorRT, batching и тестирование p95/p99.",
        "Укрепить знания распределённых систем и сетей: роль DNS, HTTP/2, QUIC, gRPC, влияние физической задержки и практики измерения latency.",
        "Научиться грамотно оформлять экспериментальные результаты: как готовить reproducible experiments, писать ablation studies и предоставлять код/скрипты.",
        "Работать над коммуникативными навыками: давать структурированные ответы, избегать троллинга/недостоверных ссылок, признавать незнание и предлагать дальнейшие шаги."
      ],
      "resources": [
        "Курсы и туториалы: https://www.coursera.org/specializations/deep-learning, https://www.fast.ai/",
        "PyTorch Tutorials: https://pytorch.org/tutorials/",
        "TensorFlow Guide: https://www.tensorflow.org/learn",
        "MLOps / deployment: https://www.kubeflow.org/, https://ml-ops.org/",
        "Инференс и оптимизация: https://developer.nvidia.com/tensorrt, https://onnx.ai/",
        "Распределённые системы и сети: https://grpc.io/docs/, https://datatracker.ietf.org/doc/html/rfc9000 (QUIC), \"Designing Data-Intensive Applications\" — M. Kleppmann",
        "Экспериментальная методология: https://arxiv.org/abs/1806.03335, \"Hidden Technical Debt in Machine Learning Systems\" — Sculley et al.",
        "Книги/руководства: \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" — A. Géron; \"Machine Learning Engineering\" / книги по MLOps"
      ]
    }
  }
}